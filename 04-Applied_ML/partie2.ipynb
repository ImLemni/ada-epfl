{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Applied ML\n",
    "\n",
    "We are going to build a classifier of news to directly assign them to 20 news categories. Note that the pipeline that you will build in this exercise could be of great help during your project if you plan to work with text!\n",
    "\n",
    "1. Load the 20newsgroup dataset. It is, again, a classic dataset that can directly be loaded using sklearn ([link](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html)).  \n",
    "[TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf), short for term frequencyâ€“inverse document frequency, is of great help when if comes to compute textual features. Indeed, it gives more importance to terms that are more specific to the considered articles (TF) but reduces the importance of terms that are very frequent in the entire corpus (IDF). Compute TF-IDF features for every article using [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Then, split your dataset into a training, a testing and a validation set (10% for validation and 10% for testing). Each observation should be paired with its corresponding label (the article category).\n",
    "\n",
    "2. Train a random forest on your training set. Try to fine-tune the parameters of your predictor on your validation set using a simple grid search on the number of estimator \"n_estimators\" and the max depth of the trees \"max_depth\". Then, display a confusion matrix of your classification pipeline. Lastly, once you assessed your model, inspect the `feature_importances_` attribute of your random forest and discuss the obtained results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import dependencies for part 2\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from email.parser import Parser as EmailParser\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the training dataset to `~/scikit_learn_data/20news_home` then load it to a variable\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset analysis\n",
    "\n",
    "[Official description](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'description'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the available keys\n",
    "newsgroups_train.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded data contains the following properties:\n",
    "\n",
    "- `data`: List of 11314 strings representing the messages.\n",
    "- `filenames`: Absolute path to the downloaded file containing the message (11314 items).\n",
    "- `target_names`: List of the names of the 20 newsgroups:\n",
    "  ```\n",
    "  ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
    "  ```\n",
    "- `target`: List of ids for the targets: from 0 to 19 referencing the targets defined in `target_names`.\n",
    "- `DESCR`: No value (`None`)\n",
    "- `description`: String describing the dataset: `'the 20 newsgroups by date dataset'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The messsages are formatted as emails: they have a header followed by a blank line and then the body with the actual text content. \n",
    "For example, you can view the message with the id `0` below.\n",
    "\n",
    "Here are some observations:\n",
    "- The most common header seem to be `From`, `Subject`, `Organization` and `Lines` \n",
    "- Messages `754`, `8000` quote other messages\n",
    "- Message `1704` seems to have an attachment (or manually pasted source code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: rec.autos\n",
      "\n",
      "From: wrat@unisql.UUCP (wharfie)\n",
      "Subject: Re: SHO clutch question (grinding noise?)\n",
      "Organization: UniSQL, Inc., Austin, Texas, USA\n",
      "Lines: 9\n",
      "\n",
      "In article <C5H6F8.LDu@news.rich.bnr.ca> jcyuhn@crchh574.NoSubdomain.NoDomain (James Yuhn) writes:\n",
      ">   That's not the clutch you're hearing, its the gearbox. Early SHOs have\n",
      ">   a lot of what is referred to as 'gear rollover' noise. You can generally\n",
      "\n",
      "\tI have one of the first SHOs built, and _mine_ doesn't make\n",
      "this noise.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the message id to view specific messages\n",
    "msg_id = 754\n",
    "print(f\"Category: {newsgroups_train.target_names[newsgroups_train.target[msg_id]]}\\n\")\n",
    "print(newsgroups_train.data[msg_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_header_or_none(headers, name):\n",
    "    \"\"\"\n",
    "    Tries to read the header `name` from `headers`, else returns `None`.\n",
    "    \"\"\"\n",
    "    if name in headers:\n",
    "        return headers[name]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_entry(label, label_id, subject, body, from_, organization, raw):\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"label_id\": label_id,\n",
    "        \"subject\": subject,\n",
    "        \"body\": body,\n",
    "        \"from\": from_,\n",
    "        \"organization\": organization,\n",
    "        \"raw\": raw\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_df(emails, labels, label_ids):\n",
    "    email_parser = EmailParser()\n",
    "    entries = []\n",
    "    for email, label_id in zip(emails, label_ids):\n",
    "        label = labels[label_id]\n",
    "        parsed_email = email_parser.parsestr(email, headersonly=False)\n",
    "        body = parsed_email.get_payload()\n",
    "        headers = dict(parsed_email.items())\n",
    "        subject = read_header_or_none(headers, \"Subject\")\n",
    "        from_ = read_header_or_none(headers, \"From\")\n",
    "        organization = read_header_or_none(headers, \"Organization\")\n",
    "        entry = create_entry(label, label_id, subject, body, from_, organization, email)\n",
    "        entries.append(entry)\n",
    "    return pandas.DataFrame(entries)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_df = create_df(newsgroups_train.data, newsgroups_train.target_names, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>from</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>organization</th>\n",
       "      <th>raw</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enl...</td>\n",
       "      <td>lerxst@wam.umd.edu (where's my thing)</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>7</td>\n",
       "      <td>University of Maryland, College Park</td>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>WHAT car is this!?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>guykuo@carson.u.washington.edu (Guy Kuo)</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>4</td>\n",
       "      <td>University of Washington</td>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>SI Clock Poll - Final Call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>twillis@ec.ecn.purdue.edu (Thomas E Willis)</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>4</td>\n",
       "      <td>Purdue University Engineering Computer Network</td>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>PB questions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robert J.C. Kyanko (rob@rjck.UUCP) wrote:\\n&gt; a...</td>\n",
       "      <td>jgreen@amber (Joe Green)</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>1</td>\n",
       "      <td>Harris Computer Systems Division</td>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>Re: Weitek P9000 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>jcm@head-cfa.harvard.edu (Jonathan McDowell)</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>14</td>\n",
       "      <td>Smithsonian Astrophysical Observatory, Cambrid...</td>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>Re: Shuttle Launch Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In article &lt;1r1eu1$4t@transfer.stratus.com&gt; cd...</td>\n",
       "      <td>dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>16</td>\n",
       "      <td>VTT</td>\n",
       "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
       "      <td>Re: Rewording the Second Amendment (ideas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>There were a few people who responded to my re...</td>\n",
       "      <td>bmdelane@quads.uchicago.edu (brian manning del...</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>13</td>\n",
       "      <td>University of Chicago</td>\n",
       "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
       "      <td>Brain Tumor Treatment (thanks)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DXB132@psuvm.psu.edu writes:\\n&gt;In article &lt;1ql...</td>\n",
       "      <td>bgrubb@dante.nmsu.edu (GRUBB)</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>3</td>\n",
       "      <td>New Mexico State University, Las Cruces, NM</td>\n",
       "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
       "      <td>Re: IDE vs SCSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I have win 3.0 and downloaded several icons an...</td>\n",
       "      <td>holmes7000@iscsvax.uni.edu</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>2</td>\n",
       "      <td>University of Northern Iowa</td>\n",
       "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
       "      <td>WIn 3.0 ICON HELP PLEASE!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jap10@po.CWRU.Edu (Joseph A. Pellettiere) writ...</td>\n",
       "      <td>kerr@ux1.cso.uiuc.edu (Stan Kerr)</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>4</td>\n",
       "      <td>University of Illinois at Urbana</td>\n",
       "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
       "      <td>Re: Sigma Designs Double up??</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  \\\n",
       "0   I was wondering if anyone out there could enl...   \n",
       "1  A fair number of brave souls who upgraded thei...   \n",
       "2  well folks, my mac plus finally gave up the gh...   \n",
       "3  Robert J.C. Kyanko (rob@rjck.UUCP) wrote:\\n> a...   \n",
       "4  From article <C5owCB.n3p@world.std.com>, by to...   \n",
       "5  In article <1r1eu1$4t@transfer.stratus.com> cd...   \n",
       "6  There were a few people who responded to my re...   \n",
       "7  DXB132@psuvm.psu.edu writes:\\n>In article <1ql...   \n",
       "8  I have win 3.0 and downloaded several icons an...   \n",
       "9  jap10@po.CWRU.Edu (Joseph A. Pellettiere) writ...   \n",
       "\n",
       "                                                from  \\\n",
       "0              lerxst@wam.umd.edu (where's my thing)   \n",
       "1           guykuo@carson.u.washington.edu (Guy Kuo)   \n",
       "2        twillis@ec.ecn.purdue.edu (Thomas E Willis)   \n",
       "3                           jgreen@amber (Joe Green)   \n",
       "4       jcm@head-cfa.harvard.edu (Jonathan McDowell)   \n",
       "5            dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)   \n",
       "6  bmdelane@quads.uchicago.edu (brian manning del...   \n",
       "7                      bgrubb@dante.nmsu.edu (GRUBB)   \n",
       "8                         holmes7000@iscsvax.uni.edu   \n",
       "9                  kerr@ux1.cso.uiuc.edu (Stan Kerr)   \n",
       "\n",
       "                      label  label_id  \\\n",
       "0                 rec.autos         7   \n",
       "1     comp.sys.mac.hardware         4   \n",
       "2     comp.sys.mac.hardware         4   \n",
       "3             comp.graphics         1   \n",
       "4                 sci.space        14   \n",
       "5        talk.politics.guns        16   \n",
       "6                   sci.med        13   \n",
       "7  comp.sys.ibm.pc.hardware         3   \n",
       "8   comp.os.ms-windows.misc         2   \n",
       "9     comp.sys.mac.hardware         4   \n",
       "\n",
       "                                        organization  \\\n",
       "0               University of Maryland, College Park   \n",
       "1                           University of Washington   \n",
       "2     Purdue University Engineering Computer Network   \n",
       "3                   Harris Computer Systems Division   \n",
       "4  Smithsonian Astrophysical Observatory, Cambrid...   \n",
       "5                                                VTT   \n",
       "6                              University of Chicago   \n",
       "7        New Mexico State University, Las Cruces, NM   \n",
       "8                        University of Northern Iowa   \n",
       "9                   University of Illinois at Urbana   \n",
       "\n",
       "                                                 raw  \\\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...   \n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...   \n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...   \n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...   \n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...   \n",
       "5  From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...   \n",
       "6  From: bmdelane@quads.uchicago.edu (brian manni...   \n",
       "7  From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...   \n",
       "8  From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...   \n",
       "9  From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...   \n",
       "\n",
       "                                      subject  \n",
       "0                          WHAT car is this!?  \n",
       "1                  SI Clock Poll - Final Call  \n",
       "2                             PB questions...  \n",
       "3                          Re: Weitek P9000 ?  \n",
       "4                 Re: Shuttle Launch Question  \n",
       "5  Re: Rewording the Second Amendment (ideas)  \n",
       "6              Brain Tumor Treatment (thanks)  \n",
       "7                             Re: IDE vs SCSI  \n",
       "8                   WIn 3.0 ICON HELP PLEASE!  \n",
       "9               Re: Sigma Designs Double up??  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reload the dataset without metadata\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "# Seems to completely remove some messages (754?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "features = vectorizer.fit_transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 101631)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_permutation(n: int, rand_state = None):\n",
    "    \"\"\"\n",
    "    Create a ranom permutation of size `n`.\n",
    "    \n",
    "    :param n: Size of the permutation\n",
    "    :param rand_state: Random state to use to create the permutation.\n",
    "    :return: A 1D numpy ndarray of size. It contains a permutation of integers from 0 to n-1\n",
    "    \"\"\"\n",
    "    if rand_state is None:\n",
    "        rand_state = numpy.random.RandomState()\n",
    "    return rand_state.permutation(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(features, labels, ratios, rand_state = None):\n",
    "    \"\"\"\n",
    "    Pseudo-randomly splits a dataset into smaller datasets of the provided size.\n",
    "    \n",
    "    :param features: Numpy array of features\n",
    "    :param labels: Numpy array of labels\n",
    "    :param ratios: List of sizes of the first n-1 groups expressed as ratios of\n",
    "                   the total size. The last group will have the remaining items.\n",
    "    :param rand_state: Random state used to create the permutation\n",
    "    :return: A list of groups of tuples (old_indexes, features, labels)\n",
    "    \"\"\"\n",
    "    from math import floor\n",
    "    if rand_state is None:\n",
    "        rand_state = numpy.random.RandomState()\n",
    "    \n",
    "    row_count = features.shape[0]\n",
    "    permutation = create_permutation(row_count, rand_state)\n",
    "    \n",
    "    \n",
    "    split_indexes = [0]\n",
    "    cur_ratio = 0\n",
    "    for ratio in ratios:\n",
    "        cur_ratio += ratio\n",
    "        split_index = floor(cur_ratio * row_count)\n",
    "        split_indexes.append(split_index)\n",
    "    split_indexes.append(row_count)\n",
    "    \n",
    "    result = []\n",
    "    for i in range(len(split_indexes) - 1):\n",
    "        start_index = split_indexes[i]\n",
    "        end_index = split_indexes[i + 1]\n",
    "        old_indexes = permutation[start_index:end_index]\n",
    "        cur_features = features[old_indexes]\n",
    "        cur_labels = labels[old_indexes]\n",
    "        result.append((old_indexes, cur_features, cur_labels))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = numpy.array(newsgroups_train.target)\n",
    "\n",
    "(validate, test_train) = split_data(features, labels, [0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_parameters(n_estimators, max_depth, features, labels):\n",
    "    evaluated = []\n",
    "    for _ in range(10):\n",
    "        (test, train) = split_data(features, labels, [0.1 / 0.9])\n",
    "        _, test_features, test_labels = test\n",
    "        _, train_features, train_labels = train\n",
    "\n",
    "        classifier = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "        trained_classifier = classifier.fit(train_features, train_labels)\n",
    "        predicted_test_labels = trained_classifier.predict(test_features)\n",
    "        unique_labels = numpy.unique(predicted_test_labels)\n",
    "        score = sklearn.metrics.f1_score(test_labels, predicted_test_labels, average='macro', labels=unique_labels)\n",
    "        evaluated.append((score, trained_classifier))\n",
    "\n",
    "    return sorted(evaluated)[5] # return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.30460441916819486,\n",
       " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_parameters(10, 10, test_train[1], test_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search(n_estimators_range, max_depth_range, features, labels):\n",
    "    \"\"\"\n",
    "    Performs a grid search to find the best model for our classification problem.\n",
    "    \n",
    "    Provide the values to search as ranges. The values must be strictly positive integers\n",
    "    for both parameters.\n",
    "    \"\"\"\n",
    "    from ipywidgets import FloatProgress\n",
    "    from IPython.display import display\n",
    "    \n",
    "    params_count = len(n_estimators_range) * len(max_depth_range)\n",
    "    progress_bar = FloatProgress(min=0, max=params_count) # instantiate the bar\n",
    "    display(progress_bar)\n",
    "    \n",
    "    result = None\n",
    "    cur_param = 0\n",
    "    for n_estimators in n_estimators_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            progress_bar.value = cur_param\n",
    "            score, classifier = evaluate_parameters(n_estimators, max_depth, features, labels)\n",
    "            if result is None or score > result[\"score\"]:\n",
    "                result = {\"score\": score, \"params\": (n_estimators, max_depth), \"classifier\": classifier}\n",
    "            cur_param += 1\n",
    "    progress_bar.value = params_count\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a66259377241298244a7b2c05b9a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = grid_search(range(10, 300, 50), range(10, 300, 50), test_train[1], test_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, validate_features, validate_labels = validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_validate_labels =  best[\"classifier\"].predict(validate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.f1_score(validate_labels, predicted_validate_labels, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc4e5a24d034afa931fc0ccd14cb776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
